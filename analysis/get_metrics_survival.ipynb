{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sksurv.metrics import cumulative_dynamic_auc\n",
    "from sksurv.nonparametric import CensoringDistributionEstimator\n",
    "from itertools import combinations\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from models import DiscreteNAM, NAM\n",
    "from utils import discretize, get_dataset, get_bin_counts, get_discetized_run_data_survival, get_run_data, get_ebm_run_data, get_run_data_survival\n",
    "\n",
    "sys.path.append(\"../run_scripts\")\n",
    "from epoch_functions import train_epoch_dys_pairs, test_epoch_dys_pairs, test_epoch_drsa, test_epoch_sa_transformer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(surv_preds, y_train, y_test, eval_times):\n",
    "    test_times = np.linspace(\n",
    "        max(y_train[\"time\"].min(), y_test[y_test[\"event\"] > 0][\"time\"].min()) + 1e-4,\n",
    "        min(y_train[\"time\"].max(), y_test[y_test[\"event\"] > 0][\"time\"].max()) - 1e-4,\n",
    "        1000\n",
    "    )\n",
    "    surv_preds = surv_preds[\n",
    "        :, \n",
    "        np.clip(\n",
    "            np.searchsorted(eval_times.cpu().numpy(), test_times),\n",
    "            0, surv_preds.shape[1]-1\n",
    "        )\n",
    "    ]\n",
    "    risk_preds = -1 * np.log(np.clip(surv_preds, 1e-5, 10 - 1e-5))\n",
    "    # Get time-dependent AUC\n",
    "    _, mean_auc = cumulative_dynamic_auc(y_train, y_test, risk_preds, test_times)\n",
    "    return mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_discrete_nam_(dataset, seed, split, data_dict=None, use_feature_set=True):\n",
    "    \n",
    "    # Read in model\n",
    "    model = torch.load(f\"../model_saves/discrete_nam_survival_{dataset}_seed{seed}_split{split}.pt\").to(device)\n",
    "    \n",
    "    # Read in args using yaml\n",
    "    args_id = model.params_id\n",
    "    with open(f\"../run_parameters/discrete_nam_survival_{dataset}_seed{seed}_split{split}_params{args_id}.yaml\", \"r\") as f:\n",
    "        args = yaml.safe_load(f)\n",
    "    \n",
    "    \n",
    "    if data_dict is None:\n",
    "        data_dict = \\\n",
    "            get_discetized_run_data_survival(dataset, seed=seed, split=split, max_bins=args[\"max_bins\"], use_feature_set=use_feature_set)\n",
    "        \n",
    "        \n",
    "    if use_feature_set:\n",
    "        selected_feats = data_dict[\"selected_feats\"]\n",
    "        selected_pairs = data_dict[\"selected_pairs\"]\n",
    "        \n",
    "        X_test_discrete = data_dict[\"X_test_discrete\"].iloc[:, selected_feats]\n",
    "        X_test_interactions = data_dict[\"X_test_discrete\"].values[:, selected_pairs]\n",
    "    else:\n",
    "        X_test_discrete = data_dict[\"X_test_discrete\"]\n",
    "        \n",
    "        active_feats = model.active_feats.cpu().numpy()\n",
    "        selected_pairs = list(combinations(active_feats, 2))\n",
    "        \n",
    "        X_test_interactions = X_test_discrete.values[:, selected_pairs]\n",
    "\n",
    "    batch_size = args[\"batch_size\"]\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(X_test_discrete.values),\n",
    "        torch.FloatTensor(X_test_interactions), \n",
    "        torch.BoolTensor(data_dict[\"y_test\"][\"event\"]),\n",
    "        torch.FloatTensor(data_dict[\"y_test\"][\"time\"].copy()),\n",
    "        torch.FloatTensor(data_dict[\"pcw_obs_times_test\"])\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    eval_times = data_dict[\"eval_times\"].to(device)\n",
    "    pcw_eval_times = data_dict[\"pcw_eval_times\"].to(device)\n",
    "\n",
    "    _, preds = test_epoch_dys_pairs(model, test_loader, eval_times, pcw_eval_times, model_mains=model)\n",
    "    \n",
    "    return preds, data_dict[\"y_train\"], data_dict[\"y_val\"], data_dict[\"y_test\"], eval_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_discrete_nam(dataset, seed, use_feature_set=True):\n",
    "    splits = [1, 2, 3, 4, 5]\n",
    "    # splits = [1]\n",
    "    \n",
    "    # Get the data_dict for one of the splits\n",
    "    # Since we only use the test set all the splits will have the same data\n",
    "    data_dict = get_discetized_run_data_survival(dataset, seed=seed, split=splits[0], use_feature_set=use_feature_set)\n",
    "    \n",
    "    split_preds = 0\n",
    "    for split in splits:\n",
    "        preds, y_train, y_val, y_test, eval_times = get_auc_discrete_nam_(dataset, seed, split, data_dict=data_dict, use_feature_set=use_feature_set)\n",
    "        split_preds += preds\n",
    "    \n",
    "    surv_preds = 1 - torch.sigmoid(split_preds / len(splits)).cpu().numpy()\n",
    "    \n",
    "    # y_train_auc = pd.concat([y_train, y_val])\n",
    "    y_train_auc = np.concatenate([y_train, y_val])\n",
    "    \n",
    "    return get_auc(surv_preds, y_train_auc, y_test, eval_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_drsa(dataset, seed, split, data_dict=None, use_feature_set=True):\n",
    "        \n",
    "    # Read in model\n",
    "    model = torch.load(f\"../model_saves/drsa_{dataset}_seed{seed}_split{split}.pt\").to(device)\n",
    "    \n",
    "    # Read in args using yaml\n",
    "    args_id = model.params_id\n",
    "    with open(f\"../run_parameters/drsa_{dataset}_seed{seed}_split{split}_params{args_id}.yaml\", \"r\") as f:\n",
    "        args = yaml.safe_load(f)\n",
    "    \n",
    "    if data_dict is None:\n",
    "        data_dict = \\\n",
    "            get_run_data_survival(dataset, seed=seed, split=split, preprocess=True, use_feature_set=use_feature_set)\n",
    "            \n",
    "    X_test = data_dict[\"X_test\"]\n",
    "    y_test = data_dict[\"y_test\"]\n",
    "\n",
    "    batch_size = args[\"batch_size\"]\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(X_test.values), \n",
    "        torch.BoolTensor(y_test[\"event\"]),\n",
    "        torch.FloatTensor(y_test[\"time\"].copy())\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    eval_times = data_dict[\"eval_times\"].to(device)\n",
    "\n",
    "    _, test_preds = test_epoch_drsa(model, test_loader, eval_times)\n",
    "    \n",
    "    surv_preds = torch.cumprod(1 - torch.sigmoid(test_preds).squeeze(-1), dim=1).cpu().numpy()  \n",
    "    \n",
    "    # y_train_auc = pd.concat([y_train, y_val])\n",
    "    y_train_auc = np.concatenate([data_dict[\"y_train\"], data_dict[\"y_val\"]])\n",
    "    \n",
    "    return get_auc(surv_preds, y_train_auc, y_test, eval_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_sa_transformer_(dataset, seed, split, data_dict=None, use_feature_set=True):\n",
    "        \n",
    "    # Read in model\n",
    "    model = torch.load(f\"../model_saves/sa_transformer_{dataset}_seed{seed}_split{split}.pt\").to(device)\n",
    "    \n",
    "    # Read in args using yaml\n",
    "    args_id = model.params_id\n",
    "    with open(f\"../run_parameters/sa_transformer_{dataset}_seed{seed}_split{split}_params{args_id}.yaml\", \"r\") as f:\n",
    "        args = yaml.safe_load(f)\n",
    "    \n",
    "    if data_dict is None:\n",
    "        data_dict = \\\n",
    "            get_run_data_survival(dataset, seed=seed, split=split, preprocess=True, use_feature_set=use_feature_set)\n",
    "            \n",
    "    X_test = data_dict[\"X_test\"]\n",
    "    y_test = data_dict[\"y_test\"]\n",
    "\n",
    "    batch_size = args[\"batch_size\"]\n",
    "\n",
    "    test_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(X_test.values), \n",
    "        torch.BoolTensor(y_test[\"event\"]),\n",
    "        torch.FloatTensor(y_test[\"time\"].copy())\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    eval_times = data_dict[\"eval_times\"].to(device)\n",
    "\n",
    "    _, test_preds = test_epoch_sa_transformer(model, test_loader, eval_times)\n",
    "    \n",
    "    return test_preds, data_dict[\"y_train\"], data_dict[\"y_val\"], data_dict[\"y_test\"], eval_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_sa_transformer(dataset, seed, use_feature_set=False):\n",
    "    splits = [1, 2, 3, 4, 5]\n",
    "    # splits = [1]\n",
    "    \n",
    "    # Get the data_dict for one of the splits\n",
    "    # Since we only use the test set all the splits will have the same data\n",
    "    # data_dict = get_run_data_survival(dataset, seed=seed, split=splits[0], preprocess=True, use_feature_set=use_feature_set)\n",
    "    \n",
    "    split_preds = 0\n",
    "    for split in splits:\n",
    "        print(\"SPLIT\", split)\n",
    "        preds, y_train, y_val, y_test, eval_times = get_auc_sa_transformer_(dataset, seed, split, use_feature_set=use_feature_set)\n",
    "        split_preds += preds\n",
    "\n",
    "    surv_preds = torch.cumprod(split_preds / len(splits), dim=1).cpu().numpy()\n",
    "    \n",
    "    # y_train_auc = pd.concat([y_train, y_val])\n",
    "    y_train_auc = np.concatenate([y_train, y_val])\n",
    "    \n",
    "    return get_auc(surv_preds, y_train_auc, y_test, eval_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all_cum_hazard_(ebm, x, times, monte_carlo=False):\n",
    "    x_input = pd.DataFrame(\n",
    "        np.tile(x.values.reshape(-1, 1), len(times)).T,\n",
    "        columns=list(x.index)\n",
    "    )\n",
    "    x_input[\"time\"] = times\n",
    "    preds = ebm.predict_proba(x_input)[:, 1]\n",
    "    if monte_carlo:\n",
    "        return pd.Series(\n",
    "            times * np.cumsum(preds) / np.arange(1, len(preds)+1)\n",
    "        )\n",
    "    else:\n",
    "        return pd.Series(np.cumsum(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:7\u001b[0;36m\u001b[0m\n\u001b[0;31m    []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def get_auc_ebm(dataset, seed, n_eval_times=100, use_feature_set=False):\n",
    "    \n",
    "    split_preds = 0\n",
    "    \n",
    "    with open(f\"../model_saves/ebm_{dataset}_seed{seed}.pkl\", \"rb\") as f:\n",
    "        ebm = pickle.load(f)\n",
    "       [] \n",
    "    data_dict = get_ebm_run_data(dataset, seed)\n",
    "    X_test = data_dict[\"X_test\"]\n",
    "    y_train = data_dict[\"y_train\"]\n",
    "    y_test = data_dict[\"y_test\"]\n",
    "    \n",
    "    if use_feature_set:\n",
    "        # Save selected_features to yaml\n",
    "        with open(f\"../feature_sets/coxnet_{dataset}_seed{seed}.yaml\", \"r\") as f:\n",
    "            selected_features = yaml.safe_load(f)\n",
    "        \n",
    "        # selected_features = ebm.feature_names_in_\n",
    "        \n",
    "        X_test = X_test[selected_features]\n",
    "        \n",
    "    pred_times = np.linspace(\n",
    "        max(y_train[\"time\"].min(), y_test[y_test[\"event\"]][\"time\"].min()) + 1e-4,\n",
    "        min(y_train[\"time\"].max(), y_test[y_test[\"event\"]][\"time\"].max()) - 1e-4,\n",
    "        1000\n",
    "    )\n",
    "\n",
    "    tqdm.pandas()\n",
    "    cum_hazards = X_test.progress_apply(\n",
    "        lambda row: predict_all_cum_hazard_(ebm, row, pred_times, monte_carlo=True), \n",
    "        axis=1\n",
    "    ).values\n",
    "        \n",
    "    # Get evaluation times before train/val split\n",
    "    quantiles = torch.quantile(\n",
    "        torch.FloatTensor(y_train[\"time\"].copy()),\n",
    "        torch.linspace(0, 1, n_eval_times+2)\n",
    "    )\n",
    "    eval_times = quantiles[1:-1]\n",
    "\n",
    "    surv_preds = np.exp(-cum_hazards)\n",
    "    \n",
    "    return get_auc(surv_preds, y_train, y_test, eval_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1170, 1176, 1188, 1193, 1194, 1198, 1199, 1200, 1201, 1210, 1211, 1220, 1221, 1243, 1251, 1262, 1270, 1287, 1288, 1310, 1366, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1170, 1173, 1175, 1178, 1179, 1180, 1182, 1193, 1194, 1199, 1201, 1210, 1237, 1251, 1277, 1288, 1291, 1310, 1316, 1351, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dict = get_run_data_survival(\"heart_failure_survival\", seed=11, split=1, preprocess=True, use_feature_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170123, 3907)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"X_train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SrcEmbed(\n",
       "  (w): Linear(in_features=3907, out_features=64, bias=True)\n",
       "  (norm): LayerNorm()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_model = torch.load(f\"../model_saves/sa_transformer_heart_failure_survival_seed11_split1.pt\").to(device)\n",
    "sat_model.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SA-Transformer\n",
      "Dataset: heart_failure_survival\n",
      "Seed 10\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1148, 1150, 1165, 1173, 1175, 1178, 1179, 1180, 1182, 1193, 1199, 1201, 1211, 1245, 1249, 1251, 1291, 1310, 1316, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1150, 1165, 1175, 1176, 1177, 1188, 1192, 1193, 1194, 1197, 1199, 1201, 1210, 1211, 1220, 1221, 1245, 1251, 1252, 1256, 1262, 1270, 1283, 1289, 1310, 1316, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1158, 1165, 1166, 1167, 1173, 1175, 1178, 1179, 1180, 1181, 1182, 1191, 1193, 1196, 1199, 1201, 1210, 1211, 1245, 1249, 1251, 1252, 1277, 1314, 1332, 1339, 1354, 1366, 1386] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1173, 1176, 1177, 1188, 1191, 1192, 1193, 1194, 1197, 1199, 1201, 1210, 1220, 1221, 1251, 1252, 1256, 1262, 1270, 1283, 1289, 1310, 1316, 1339, 1351, 1386, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1153, 1163, 1165, 1175, 1178, 1179, 1180, 1181, 1182, 1188, 1191, 1196, 1197, 1198, 1200, 1201, 1211, 1221, 1239, 1243, 1245, 1277, 1278, 1291, 1332, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1176, 1177, 1182, 1188, 1191, 1192, 1193, 1194, 1196, 1197, 1199, 1201, 1210, 1220, 1221, 1239, 1251, 1252, 1256, 1262, 1270, 1283, 1289, 1310, 1316, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1153, 1165, 1170, 1173, 1201, 1221, 1243, 1245, 1251, 1277, 1287, 1288, 1310, 1314] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1176, 1177, 1188, 1192, 1193, 1194, 1197, 1199, 1201, 1210, 1220, 1221, 1251, 1252, 1256, 1262, 1270, 1283, 1289, 1310, 1316, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1136, 1153, 1165, 1179, 1191, 1193, 1194, 1196, 1197, 1198, 1200, 1201, 1288, 1289, 1291, 1305, 1310, 1314, 1354, 1371, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1136, 1165, 1176, 1177, 1188, 1191, 1192, 1193, 1194, 1196, 1197, 1199, 1201, 1210, 1220, 1221, 1251, 1252, 1256, 1262, 1270, 1283, 1288, 1289, 1305, 1310, 1316, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 11\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1170, 1176, 1188, 1193, 1194, 1198, 1199, 1200, 1201, 1210, 1211, 1220, 1221, 1243, 1251, 1262, 1270, 1287, 1288, 1310, 1366, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1170, 1173, 1175, 1178, 1179, 1180, 1182, 1193, 1194, 1199, 1201, 1210, 1237, 1251, 1277, 1288, 1291, 1310, 1316, 1351, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1136, 1165, 1175, 1177, 1179, 1180, 1182, 1184, 1188, 1191, 1193, 1196, 1197, 1199, 1201, 1245, 1251, 1330, 1332, 1339, 1388] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1170, 1173, 1175, 1178, 1179, 1180, 1182, 1191, 1193, 1194, 1196, 1199, 1201, 1210, 1237, 1251, 1277, 1288, 1291, 1316, 1330, 1339, 1351, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1153, 1166, 1182, 1188, 1191, 1196, 1201, 1239, 1262, 1310, 1332] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1170, 1173, 1175, 1178, 1179, 1180, 1182, 1191, 1193, 1194, 1196, 1199, 1201, 1210, 1237, 1239, 1251, 1277, 1288, 1291, 1316, 1351, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1150, 1152, 1153, 1165, 1177, 1178, 1179, 1180, 1181, 1182, 1192, 1193, 1199, 1201, 1220, 1221, 1243, 1245, 1249, 1277, 1293, 1314, 1318, 1366, 1371] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1152, 1153, 1165, 1170, 1173, 1175, 1178, 1179, 1180, 1182, 1192, 1193, 1194, 1199, 1201, 1210, 1237, 1251, 1277, 1288, 1291, 1316, 1351, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1153, 1165, 1166, 1175, 1176, 1179, 1198, 1200, 1201, 1211, 1245, 1249, 1251, 1277, 1289, 1310, 1354, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1170, 1173, 1175, 1178, 1179, 1180, 1182, 1193, 1194, 1199, 1201, 1210, 1237, 1245, 1251, 1277, 1288, 1291, 1310, 1316, 1351, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 12\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1156, 1165, 1175, 1180, 1182, 1188, 1191, 1193, 1196, 1198, 1199, 1200, 1201, 1208, 1245, 1251, 1252, 1256, 1262, 1270, 1371, 1374, 1386, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1166, 1175, 1178, 1179, 1180, 1181, 1182, 1196, 1199, 1201, 1221, 1251, 1277, 1283, 1287, 1288, 1289, 1310, 1314, 1316, 1332, 1351, 1371, 1374, 1386, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1163, 1165, 1170, 1178, 1179, 1180, 1181, 1182, 1184, 1188, 1191, 1201, 1208, 1220, 1221, 1256, 1262, 1305, 1310, 1314, 1374] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1166, 1175, 1178, 1179, 1180, 1181, 1182, 1184, 1196, 1201, 1221, 1251, 1277, 1283, 1287, 1288, 1289, 1310, 1314, 1316, 1332, 1351, 1374, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1167, 1170, 1175, 1178, 1181, 1182, 1188, 1191, 1193, 1194, 1196, 1197, 1201, 1211, 1220, 1221, 1243, 1245, 1278, 1310, 1354, 1366, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1166, 1175, 1178, 1179, 1180, 1181, 1182, 1196, 1201, 1221, 1251, 1277, 1283, 1287, 1288, 1289, 1310, 1314, 1316, 1332, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1148, 1150, 1165, 1175, 1178, 1180, 1182, 1188, 1191, 1193, 1196, 1199, 1201, 1220, 1221, 1243, 1245, 1251, 1252, 1289, 1310, 1318, 1366, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1166, 1175, 1178, 1179, 1180, 1181, 1182, 1196, 1199, 1201, 1221, 1245, 1251, 1277, 1283, 1287, 1288, 1289, 1310, 1314, 1316, 1332, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1163, 1165, 1175, 1177, 1178, 1180, 1181, 1182, 1191, 1193, 1201, 1210, 1211, 1245, 1249, 1251, 1262, 1278, 1347, 1354, 1385, 1386] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1166, 1175, 1178, 1179, 1180, 1181, 1182, 1196, 1201, 1211, 1221, 1251, 1277, 1283, 1287, 1288, 1289, 1310, 1314, 1316, 1332, 1347, 1351, 1386, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 13\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1150, 1153, 1165, 1170, 1174, 1175, 1177, 1178, 1181, 1182, 1196, 1198, 1200, 1201, 1208, 1210, 1215, 1251, 1310, 1314, 1318, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1150, 1156, 1165, 1166, 1174, 1175, 1178, 1180, 1188, 1193, 1197, 1199, 1201, 1215, 1251, 1252, 1262, 1310, 1314, 1316, 1318, 1332, 1366, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1153, 1158, 1165, 1175, 1176, 1178, 1180, 1181, 1182, 1184, 1193, 1199, 1201, 1215, 1220, 1221, 1237, 1245, 1251, 1262, 1270, 1277, 1293, 1310, 1316, 1330, 1351, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1156, 1165, 1166, 1175, 1178, 1180, 1181, 1184, 1188, 1193, 1197, 1199, 1201, 1215, 1220, 1221, 1245, 1251, 1252, 1262, 1293, 1314, 1316, 1330, 1332, 1366, 1388] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1153, 1158, 1163, 1165, 1173, 1175, 1179, 1181, 1192, 1193, 1194, 1197, 1199, 1201, 1208, 1210, 1211, 1213, 1221, 1237, 1244, 1245, 1262, 1283, 1289, 1354, 1371] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1156, 1165, 1166, 1175, 1178, 1180, 1181, 1188, 1192, 1193, 1194, 1197, 1199, 1201, 1245, 1251, 1252, 1262, 1314, 1316, 1332, 1366, 1388] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1165, 1167, 1175, 1178, 1179, 1180, 1181, 1182, 1191, 1193, 1194, 1196, 1201, 1211, 1215, 1220, 1221, 1245, 1251, 1278, 1283, 1289, 1310, 1318, 1366, 1371] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1156, 1165, 1166, 1175, 1178, 1180, 1188, 1193, 1197, 1199, 1201, 1215, 1220, 1221, 1245, 1251, 1252, 1262, 1283, 1310, 1314, 1316, 1318, 1332, 1366, 1388] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1167, 1170, 1173, 1175, 1179, 1180, 1182, 1191, 1192, 1201, 1245, 1251, 1278, 1283, 1288, 1310, 1314, 1316, 1330, 1351, 1366, 1371] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1156, 1165, 1166, 1175, 1178, 1179, 1180, 1188, 1192, 1193, 1197, 1199, 1201, 1245, 1251, 1252, 1262, 1288, 1314, 1316, 1330, 1332, 1366, 1371, 1388] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 14\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1163, 1165, 1166, 1173, 1179, 1180, 1182, 1196, 1197, 1201, 1221, 1237, 1245, 1249, 1251, 1252, 1277, 1305, 1310, 1351, 1366, 1371, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1150, 1153, 1158, 1165, 1166, 1170, 1175, 1178, 1179, 1182, 1188, 1196, 1199, 1201, 1220, 1221, 1243, 1251, 1252, 1270, 1277, 1288, 1305, 1310, 1314, 1332, 1366, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1138, 1141, 1153, 1165, 1167, 1173, 1175, 1177, 1180, 1188, 1191, 1193, 1194, 1196, 1199, 1201, 1245, 1249, 1251, 1256, 1262, 1277, 1310, 1314, 1330, 1366, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1138, 1148, 1150, 1153, 1158, 1165, 1166, 1170, 1175, 1178, 1179, 1182, 1188, 1199, 1201, 1220, 1221, 1243, 1270, 1277, 1288, 1310, 1314, 1332, 1366] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1152, 1163, 1165, 1178, 1180, 1193, 1196, 1201, 1211, 1234, 1252, 1256, 1262, 1278, 1289, 1291, 1316, 1330, 1335, 1351, 1366, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1150, 1152, 1153, 1158, 1165, 1166, 1170, 1175, 1178, 1179, 1182, 1188, 1199, 1201, 1211, 1220, 1221, 1234, 1243, 1252, 1270, 1288, 1310, 1314, 1316, 1332, 1335, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1165, 1167, 1175, 1178, 1179, 1180, 1181, 1182, 1188, 1193, 1196, 1199, 1201, 1210, 1221, 1245, 1251, 1252, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1150, 1153, 1158, 1165, 1166, 1170, 1175, 1178, 1179, 1182, 1188, 1199, 1201, 1220, 1221, 1243, 1245, 1270, 1288, 1310, 1314, 1332, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [330, 1156, 1163, 1165, 1175, 1178, 1179, 1180, 1181, 1182, 1191, 1196, 1198, 1200, 1201, 1211, 1237, 1245, 1251, 1252, 1277, 1289, 1291, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1148, 1150, 1153, 1158, 1165, 1166, 1170, 1175, 1178, 1179, 1182, 1188, 1199, 1201, 1220, 1221, 1243, 1245, 1270, 1277, 1288, 1310, 1314, 1332] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "models = [\"SA-Transformer\"]\n",
    "datasets = [\"heart_failure_survival\"]\n",
    "seeds = [10, 11, 12, 13, 14]\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        if dataset == \"heart_failure_survival\":\n",
    "            use_feature_set = True\n",
    "        else:\n",
    "            use_feature_set = False\n",
    "        \n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for seed in seeds:\n",
    "            print(\"Seed\", seed)\n",
    "            if model == \"EBM\":\n",
    "                auc = get_auc_ebm(dataset, seed, use_feature_set=use_feature_set)\n",
    "                \n",
    "            elif model == \"Discrete_NAM\":\n",
    "                auc = get_auc_discrete_nam(dataset, seed, use_feature_set=use_feature_set)\n",
    "                \n",
    "            elif model == \"SA-Transformer\":\n",
    "                auc = get_auc_sa_transformer(dataset, seed)\n",
    "                \n",
    "            results.append([\n",
    "                model, dataset, seed, auc\n",
    "            ])\n",
    "            \n",
    "results = pd.DataFrame(results, columns=[\"model\", \"dataset\", \"seed\", \"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model           dataset               \n",
       "SA-Transformer  heart_failure_survival    0.860 ± 0.003\n",
       "Name: auc, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = results.groupby([\"model\", \"dataset\"])[\"auc\"].mean()\n",
    "std_df = results.groupby([\"model\", \"dataset\"])[\"auc\"].std()\n",
    "\n",
    "means_df = mean_df.round(3).map(\"{:.3f}\".format)\n",
    "stds_df = std_df.round(3).map(\"{:.3f}\".format)\n",
    "\n",
    "# Convert to string and add plus/minus in between\n",
    "means_df.astype(str) + \" ± \" + stds_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SA-Transformer\n",
      "Dataset: unos\n",
      "Seed 10\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 11\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 12\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 13\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 14\n",
      "SPLIT 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPLIT 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    }
   ],
   "source": [
    "models = [\"SA-Transformer\"]\n",
    "datasets = [\"unos\"]\n",
    "seeds = [10, 11, 12, 13, 14]\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        if dataset == \"heart_failure_survival\":\n",
    "            use_feature_set = True\n",
    "        else:\n",
    "            use_feature_set = False\n",
    "        \n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for seed in seeds:\n",
    "            print(\"Seed\", seed)\n",
    "            if model == \"EBM\":\n",
    "                auc = get_auc_ebm(dataset, seed, use_feature_set=use_feature_set)\n",
    "                \n",
    "            elif model == \"Discrete_NAM\":\n",
    "                auc = get_auc_discrete_nam(dataset, seed, use_feature_set=use_feature_set)\n",
    "                \n",
    "            elif model == \"SA-Transformer\":\n",
    "                auc = get_auc_sa_transformer(dataset, seed)\n",
    "                \n",
    "            results.append([\n",
    "                model, dataset, seed, auc\n",
    "            ])\n",
    "            \n",
    "results_unos = pd.DataFrame(results, columns=[\"model\", \"dataset\", \"seed\", \"auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model           dataset\n",
       "SA-Transformer  unos       0.714 ± 0.002\n",
       "Name: auc, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = results_unos.groupby([\"model\", \"dataset\"])[\"auc\"].mean()\n",
    "std_df = results_unos.groupby([\"model\", \"dataset\"])[\"auc\"].std()\n",
    "\n",
    "means_df = mean_df.round(3).map(\"{:.3f}\".format)\n",
    "stds_df = std_df.round(3).map(\"{:.3f}\".format)\n",
    "\n",
    "# Convert to string and add plus/minus in between\n",
    "means_df.astype(str) + \" ± \" + stds_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">seed</th>\n",
       "      <th colspan=\"2\" halign=\"left\">auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">EBM</th>\n",
       "      <th>heart_failure_survival</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.834311</td>\n",
       "      <td>0.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.581139</td>\n",
       "      <td>0.808115</td>\n",
       "      <td>0.007501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              seed                 auc          \n",
       "                              mean       std      mean       std\n",
       "model dataset                                                   \n",
       "EBM   heart_failure_survival  12.0  1.581139  0.834311  0.003518\n",
       "      support                 12.0  1.581139  0.808115  0.007501"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"model\", \"dataset\", \"seed\", \"auc\"])\n",
    "results_df.groupby([\"model\", \"dataset\"]).agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SA-Transformer\n",
      "Dataset: unos\n"
     ]
    }
   ],
   "source": [
    "models = [\"SA-Transformer\"]\n",
    "datasets = [\"unos\"]\n",
    "seeds = [10, 11, 12, 13, 14]\n",
    "splits = [1, 2, 3, 4, 5]\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")\n",
    "    for dataset in datasets:\n",
    "        \n",
    "        if dataset == \"heart_failure_survival\":\n",
    "            use_feature_set = True\n",
    "        else:\n",
    "            use_feature_set = False\n",
    "        \n",
    "        print(f\"Dataset: {dataset}\")\n",
    "        for seed in seeds:\n",
    "            if model == \"EBM\":\n",
    "                # auc = get_auc_ebm(dataset, seed, use_feature_set=use_feature_set)\n",
    "                with open(f\"../model_saves/ebm_{dataset}_seed{seed}.pkl\", \"rb\") as f:\n",
    "                    ebm = pickle.load(f)\n",
    "                    \n",
    "                fit_time = ebm.fit_time\n",
    "                \n",
    "            elif model == \"Discrete_NAM\":\n",
    "                fit_time = 0\n",
    "                for split in splits:\n",
    "                    nam = torch.load(f\"../model_saves/discrete_nam_survival_{dataset}_seed{seed}_split{split}.pt\")\n",
    "                    fit_time += nam.fit_time\n",
    "                    \n",
    "            elif model == \"SA-Transformer\":\n",
    "                fit_time = 0\n",
    "                for split in splits:\n",
    "                    nam = torch.load(f\"../model_saves/sa_transformer_{dataset}_seed{seed}_split{split}.pt\")\n",
    "                    fit_time += nam.fit_time\n",
    "                \n",
    "            results.append([\n",
    "                model, dataset, seed, fit_time / 60\n",
    "            ])\n",
    "            \n",
    "results = pd.DataFrame(results, columns=[\"model\", \"dataset\", \"seed\", \"fit_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model           dataset\n",
       "SA-Transformer  unos       199.160 ± 13.076\n",
       "Name: fit_time, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_df = results.groupby([\"model\", \"dataset\"])[\"fit_time\"].mean()\n",
    "std_df = results.groupby([\"model\", \"dataset\"])[\"fit_time\"].std()\n",
    "\n",
    "means_df = mean_df.round(3).map(\"{:.3f}\".format)\n",
    "stds_df = std_df.round(3).map(\"{:.3f}\".format)\n",
    "\n",
    "# Convert to string and add plus/minus in between\n",
    "means_df.astype(str) + \" ± \" + stds_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt     education  education-num  \\\n",
       "0       25       Private  226802          11th              7   \n",
       "1       38       Private   89814       HS-grad              9   \n",
       "2       28     Local-gov  336951    Assoc-acdm             12   \n",
       "3       44       Private  160323  Some-college             10   \n",
       "4       18           NaN  103497  Some-college             10   \n",
       "...    ...           ...     ...           ...            ...   \n",
       "48837   27       Private  257302    Assoc-acdm             12   \n",
       "48838   40       Private  154374       HS-grad              9   \n",
       "48839   58       Private  151910       HS-grad              9   \n",
       "48840   22       Private  201490       HS-grad              9   \n",
       "48841   52  Self-emp-inc  287927       HS-grad              9   \n",
       "\n",
       "           marital-status         occupation relationship   race     sex  \\\n",
       "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
       "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
       "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
       "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
       "4           Never-married                NaN    Own-child  White  Female   \n",
       "...                   ...                ...          ...    ...     ...   \n",
       "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
       "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
       "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
       "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
       "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  \n",
       "0                 0             0              40  United-States  \n",
       "1                 0             0              50  United-States  \n",
       "2                 0             0              40  United-States  \n",
       "3              7688             0              40  United-States  \n",
       "4                 0             0              30  United-States  \n",
       "...             ...           ...             ...            ...  \n",
       "48837             0             0              38  United-States  \n",
       "48838             0             0              40  United-States  \n",
       "48839             0             0              40  United-States  \n",
       "48840             0             0              20  United-States  \n",
       "48841         15024             0              40  United-States  \n",
       "\n",
       "[48842 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_dataset('adult')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4.884200e+04\n",
       "mean     1.896641e+05\n",
       "std      1.056040e+05\n",
       "min      1.228500e+04\n",
       "25%      1.175505e+05\n",
       "50%      1.781445e+05\n",
       "75%      2.376420e+05\n",
       "max      1.490400e+06\n",
       "Name: fnlwgt, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"fnlwgt\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1148, 1150, 1165, 1173, 1175, 1178, 1179, 1180, 1182, 1193, 1199, 1201, 1211, 1245, 1249, 1251, 1291, 1310, 1316, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1150, 1165, 1175, 1176, 1177, 1188, 1192, 1193, 1194, 1197, 1199, 1201, 1210, 1211, 1220, 1221, 1245, 1251, 1252, 1256, 1262, 1270, 1283, 1289, 1310, 1316, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dict = \\\n",
    "    get_run_data_survival(dataset, seed=seed, split=split, preprocess=True, use_feature_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8555127994793543"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat_auc = get_auc_sa_transformer(dataset, seed, split, data_dict=data_dict, use_feature_set=False)\n",
    "sat_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7133271415103789"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"unos\"\n",
    "seed = 10\n",
    "split = 1\n",
    "\n",
    "sat_auc = get_auc_sa_transformer(dataset, seed, split, use_feature_set=False)\n",
    "sat_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7167600645391862"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"unos\"\n",
    "seed = 10\n",
    "split = 1\n",
    "\n",
    "dnam_auc = get_auc_discrete_nam(dataset, seed, use_feature_set=False)\n",
    "dnam_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1148, 1150, 1165, 1173, 1175, 1178, 1179, 1180, 1182, 1193, 1199, 1201, 1211, 1245, 1249, 1251, 1291, 1310, 1316, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1150, 1165, 1175, 1176, 1177, 1188, 1192, 1193, 1194, 1197, 1199, 1201, 1210, 1211, 1220, 1221, 1245, 1251, 1252, 1256, 1262, 1270, 1283, 1289, 1310, 1316, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8164614272677884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"heart_failure_survival\"\n",
    "seed = 10\n",
    "split = 1\n",
    "\n",
    "drsa_auc = get_auc_drsa(dataset, seed, split, use_feature_set=False)\n",
    "drsa_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1141, 1148, 1150, 1165, 1173, 1175, 1178, 1179, 1180, 1182, 1193, 1199, 1201, 1211, 1245, 1249, 1251, 1291, 1310, 1316, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/default_torch/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:228: UserWarning: Found unknown categories in columns [1150, 1165, 1175, 1176, 1177, 1188, 1192, 1193, 1194, 1197, 1199, 1201, 1210, 1211, 1220, 1221, 1245, 1251, 1252, 1256, 1262, 1270, 1283, 1289, 1310, 1316, 1351, 1388, 1392] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n",
      "                                       \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (128) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      3\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 5\u001b[0m drsa_auc \u001b[38;5;241m=\u001b[39m \u001b[43mget_auc_sa_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_feature_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m drsa_auc\n",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m, in \u001b[0;36mget_auc_sa_transformer\u001b[0;34m(dataset, seed, split, data_dict, use_feature_set)\u001b[0m\n\u001b[1;32m     25\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     27\u001b[0m eval_times \u001b[38;5;241m=\u001b[39m data_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_times\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 29\u001b[0m _, test_preds \u001b[38;5;241m=\u001b[39m \u001b[43mtest_epoch_sa_transformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m surv_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcumprod(test_preds, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# y_train_auc = pd.concat([y_train, y_val])\u001b[39;00m\n",
      "File \u001b[0;32m/home/jupyter/python_scripts/discrete_nam/experimental/analysis/../run_scripts/epoch_functions.py:329\u001b[0m, in \u001b[0;36mtest_epoch_sa_transformer\u001b[0;34m(model, test_loader, eval_times)\u001b[0m\n\u001b[1;32m    325\u001b[0m         preds\u001b[38;5;241m.\u001b[39mappend(y_pred\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m    327\u001b[0m         surv_probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcumprod(y_pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 329\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mbce_surv_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurv_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_times\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader), torch\u001b[38;5;241m.\u001b[39mcat(preds)\n",
      "File \u001b[0;32m/home/jupyter/python_scripts/discrete_nam/experimental/analysis/../run_scripts/loss_fns.py:78\u001b[0m, in \u001b[0;36mbce_surv_loss\u001b[0;34m(surv_preds, events, times, eval_times)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbce_surv_loss\u001b[39m(surv_preds, events, times, eval_times):\n\u001b[1;32m     71\u001b[0m     \n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# surv_preds is of shape (N, T)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# Maximize survival for all samples before their times\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m---> 78\u001b[0m         \u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43msurv_preds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_times\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     80\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Minimize survival loss for all uncensored samples after their times\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m surv_preds \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m) \u001b[38;5;241m*\u001b[39m \\\n\u001b[1;32m     86\u001b[0m         torch\u001b[38;5;241m.\u001b[39mlogical_and(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     91\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (128) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "dataset = \"heart_failure_survival\"\n",
    "seed = 10\n",
    "split = 1\n",
    "\n",
    "drsa_auc = get_auc_sa_transformer(dataset, seed, split, use_feature_set=False)\n",
    "drsa_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">AUC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DiscreteNAM</th>\n",
       "      <td>0.843652</td>\n",
       "      <td>0.002705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AUC          \n",
       "                 mean       std\n",
       "Model                          \n",
       "DiscreteNAM  0.843652  0.002705"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"heart_failure_survival\"\n",
    "seeds = [10, 11, 12, 13, 14]\n",
    "aucs = []\n",
    "for seed in seeds:\n",
    "    auc = get_auc_discrete_nam(dataset, seed)\n",
    "    aucs.append(auc)\n",
    "\n",
    "aucs = pd.DataFrame(aucs, columns=[\"AUC\"])\n",
    "aucs[\"Model\"] = \"DiscreteNAM\"\n",
    "\n",
    "aucs.groupby(\"Model\").agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841135</td>\n",
       "      <td>DiscreteNAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.842667</td>\n",
       "      <td>DiscreteNAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.847954</td>\n",
       "      <td>DiscreteNAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.841998</td>\n",
       "      <td>DiscreteNAM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.844508</td>\n",
       "      <td>DiscreteNAM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC        Model\n",
       "0  0.841135  DiscreteNAM\n",
       "1  0.842667  DiscreteNAM\n",
       "2  0.847954  DiscreteNAM\n",
       "3  0.841998  DiscreteNAM\n",
       "4  0.844508  DiscreteNAM"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "auc = get_auc_discrete_nam(\"heart_failure_survival\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8407390195549266"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53164/53164 [05:23<00:00, 164.36it/s]\n"
     ]
    }
   ],
   "source": [
    "ebm_auc = get_auc_ebm(\"heart_failure_survival\", 12, use_feature_set=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8391356798950814"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8428519870451628"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1821/1821 [00:40<00:00, 44.60it/s]\n"
     ]
    }
   ],
   "source": [
    "ebm_auc = get_auc_ebm(\"support\", 10, use_feature_set=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1821 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1821/1821 [00:46<00:00, 39.05it/s]\n",
      "100%|██████████| 1821/1821 [00:32<00:00, 56.77it/s]\n",
      "100%|██████████| 1821/1821 [00:46<00:00, 38.86it/s]\n",
      "100%|██████████| 1821/1821 [00:46<00:00, 38.79it/s]\n",
      "100%|██████████| 1821/1821 [00:39<00:00, 45.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6621206961715033 0.009496662233958645\n"
     ]
    }
   ],
   "source": [
    "dataset = \"support\"\n",
    "seeds = [10, 11, 12, 13, 14]\n",
    "aucs = []\n",
    "for seed in seeds:\n",
    "    auc = get_auc_ebm(dataset, seed)\n",
    "    aucs.append(auc)\n",
    "    \n",
    "print(np.mean(aucs), np.std(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10719.62092385292, 414.15938192756215, 2227.926358985901, 235.66472519167203)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"heart_failure_survival\"\n",
    "seeds = [10, 11, 12, 13, 14]\n",
    "splits = [1, 2, 3, 4, 5]\n",
    "\n",
    "ebm_times = []\n",
    "for seed in seeds:\n",
    "    with open(f\"../model_saves/ebm_{dataset}_seed{seed}.pkl\", \"rb\") as f:\n",
    "        ebm = pickle.load(f)\n",
    "    ebm_times.append(ebm.fit_time)\n",
    "    \n",
    "dnam_times = []\n",
    "for seed in seeds:\n",
    "    dnam_time = 0\n",
    "    for split in splits:\n",
    "        model = torch.load(f\"../model_saves/discrete_nam_survival_{dataset}_seed{seed}_split{split}.pt\")\n",
    "        dnam_time += model.fit_time\n",
    "    dnam_times.append(dnam_time)\n",
    "    \n",
    "np.mean(ebm_times), np.std(ebm_times), np.mean(dnam_times), np.std(dnam_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8401130087869512"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnam_auc = get_auc_discrete_nam(\"heart_failure_survival\", 10)\n",
    "dnam_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"heart_failure_survival\"\n",
    "seed = 10\n",
    "\n",
    "with open(f\"../model_saves/ebm_{dataset}_seed{seed}.pkl\", \"rb\") as f:\n",
    "    ebm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ebm.feature_names_in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ebm.fit_time // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8250152203486563"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = get_auc_discrete_nam(\"support\", 11, use_feature_set=False)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"heart_failure_survival\"\n",
    "seed = 10\n",
    "split = 1\n",
    "use_feature_set = True\n",
    "\n",
    "data_dict = get_discetized_run_data_survival(dataset, seed=seed, split=split, max_bins=32, use_feature_set=use_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86427     1\n",
       "146253    1\n",
       "181480    1\n",
       "100195    1\n",
       "37023     1\n",
       "         ..\n",
       "210536    1\n",
       "20339     1\n",
       "191396    2\n",
       "33482     1\n",
       "116877    1\n",
       "Name: condition_long_term_201826, Length: 170123, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"X_train_discrete\"][\"condition_long_term_201826\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict[\"selected_feats\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat_meas:3050380_0', 'smoking'], dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"X_train_discrete\"].columns[data_dict[\"cat_cols_indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c for c in data_dict[\"X_train_discrete\"].columns if \"gender\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"X_train_discrete\"].select_dtypes(include=\"category\").columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
